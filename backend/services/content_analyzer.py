"""
–ú–æ–¥—É–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏ –ø–æ–∏—Å–∫–∞ –ª—É—á—à–∏—Ö –∏–¥–µ–π –¥–ª—è YouTube –≤–∏–¥–µ–æ

–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:
- –ü–æ–∏—Å–∫ —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö –∏ –≤–∏—Ä—É—Å–Ω—ã—Ö –∏–¥–µ–π –¥–ª—è –≤–∏–¥–µ–æ
- –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –∏ –∏—Ö —É—Å–ø–µ—à–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
- –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏–∑ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ç–µ–º
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –∏–¥–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
- –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–¥–µ–π –ø–æ –≤–∏—Ä—É—Å–Ω–æ–º—É –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—É
- –ê–Ω–∞–ª–∏–∑ —Å–µ–∑–æ–Ω–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
- YouTube Data API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ
- Google Gemini –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–¥–µ–π
- APIKeyManager –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–ª—é—á–∞–º–∏
"""

import sys
import os
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.insert(0, str(Path(__file__).parent.parent))

from services.api_key_manager import APIKeyManager
from services.analyzer import YouTubeAnalyzer, YouTubeAnalyzerError
import google.generativeai as genai
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timedelta
from collections import Counter
import re
import asyncio


class ContentAnalyzerError(Exception):
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ—à–∏–±–æ–∫ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
    pass


class ContentAnalyzer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏ –ø–æ–∏—Å–∫–∞ –ª—É—á—à–∏—Ö –∏–¥–µ–π –¥–ª—è –≤–∏–¥–µ–æ

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç YouTube API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤ –∏ Google Gemini –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–¥–µ–π
    """

    def __init__(
        self,
        api_key_manager: APIKeyManager,
        youtube_analyzer: Optional[YouTubeAnalyzer] = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞

        Args:
            api_key_manager: –ú–µ–Ω–µ–¥–∂–µ—Ä API –∫–ª—é—á–µ–π
            youtube_analyzer: YouTube –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, —Å–æ–∑–¥–∞—ë—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)

        Raises:
            ContentAnalyzerError: –ü—Ä–∏ –æ—à–∏–±–∫–∞—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        """
        try:
            self.api_key_manager = api_key_manager

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º YouTube –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
            if youtube_analyzer:
                self.youtube_analyzer = youtube_analyzer
            else:
                youtube_key = self.api_key_manager.get_youtube_key()
                self.youtube_analyzer = YouTubeAnalyzer(youtube_key)

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Gemini –∫–ª–∏–µ–Ω—Ç
            gemini_key = self.api_key_manager.get_gemini_key()
            genai.configure(api_key=gemini_key)
            self.gemini_model = genai.GenerativeModel("gemini-1.5-flash")

            print("‚úÖ ContentAnalyzer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

        except Exception as e:
            raise ContentAnalyzerError(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ ContentAnalyzer: {str(e)}")

    async def find_best_video_ideas(
        self,
        niche: str,
        num_ideas: int = 10,
        analyze_competitors: bool = True
    ) -> List[Dict]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç –ª—É—á—à–∏–µ –∏–¥–µ–∏ –¥–ª—è –≤–∏–¥–µ–æ –≤ –∑–∞–¥–∞–Ω–Ω–æ–π –Ω–∏—à–µ

        –ü—Ä–æ—Ü–µ—Å—Å:
        1. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–æ–ø–æ–≤—ã–µ –≤–∏–¥–µ–æ –≤ –Ω–∏—à–µ (–µ—Å–ª–∏ analyze_competitors=True)
        2. –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã —É—Å–ø–µ—à–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–µ –∏–¥–µ–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        4. –†–∞–Ω–∂–∏—Ä—É–µ—Ç –∏–¥–µ–∏ –ø–æ –≤–∏—Ä—É—Å–Ω–æ–º—É –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—É

        Args:
            niche: –ù–∏—à–∞ (—Ç–µ–º–∞) –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–ø—Å–∏—Ö–æ–ª–æ–≥–∏—è", "productivity")
            num_ideas: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–¥–µ–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10)
            analyze_competitors: –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True)

        Returns:
            List[Dict]: –°–ø–∏—Å–æ–∫ –∏–¥–µ–π, –∫–∞–∂–¥–∞—è —Å–æ–¥–µ—Ä–∂–∏—Ç:
                - title: –ó–∞–≥–æ–ª–æ–≤–æ–∫ –≤–∏–¥–µ–æ
                - description: –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
                - viral_score: –û—Ü–µ–Ω–∫–∞ –≤–∏—Ä—É—Å–Ω–æ–≥–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ (0-100)
                - target_audience: –¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è
                - hook: –ó–∞—Ö–≤–∞—Ç—ã–≤–∞—é—â–∏–π —Ö—É–∫ –¥–ª—è –≤–∏–¥–µ–æ
                - estimated_views: –ü—Ä–∏–º–µ—Ä–Ω—ã–µ –ø—Ä–æ—Å–º–æ—Ç—Ä—ã
                - difficulty: –°–ª–æ–∂–Ω–æ—Å—Ç—å —Å–æ–∑–¥–∞–Ω–∏—è (easy/medium/hard)

        Raises:
            ContentAnalyzerError: –ü—Ä–∏ –æ—à–∏–±–∫–∞—Ö –∞–Ω–∞–ª–∏–∑–∞
        """
        try:
            print(f"\nüîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –Ω–∏—à—É: {niche}")
            print(f"   –ì–µ–Ω–µ—Ä–∏—Ä—É—é {num_ideas} –∏–¥–µ–π...")

            patterns = {}
            trending_topics = []

            # –®–∞–≥ 1: –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ (–µ—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω)
            if analyze_competitors:
                print("   üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤...")

                # –ò—â–µ–º —Ç–æ–ø–æ–≤—ã–µ –≤–∏–¥–µ–æ –≤ –Ω–∏—à–µ
                try:
                    request = self.youtube_analyzer.youtube.search().list(
                        part='snippet',
                        q=niche,
                        type='video',
                        maxResults=20,
                        order='viewCount',
                        publishedAfter=(datetime.now() - timedelta(days=90)).isoformat() + 'Z'
                    )
                    response = request.execute()

                    # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–º—ã –∏–∑ —É—Å–ø–µ—à–Ω—ã—Ö –≤–∏–¥–µ–æ
                    trending_topics = []
                    video_performances = []

                    for item in response['items']:
                        video_id = item['id']['videoId']
                        title = item['snippet']['title']
                        trending_topics.append({
                            'title': title,
                            'video_id': video_id
                        })

                        # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤–∏–¥–µ–æ
                        try:
                            performance = await self.youtube_analyzer.analyze_video_performance(video_id)
                            video_performances.append({
                                'title': title,
                                'performance': self._calculate_performance(performance)
                            })
                        except:
                            continue

                    print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(trending_topics)} —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö –≤–∏–¥–µ–æ")

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
                    patterns = self._extract_patterns(trending_topics)

                except Exception as e:
                    print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤: {e}")
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤

            # –®–∞–≥ 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–¥–µ–π
            print("   ü§ñ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–¥–µ–∏ —Å –ø–æ–º–æ—â—å—é AI...")
            ideas = await self._generate_ideas_from_patterns(patterns, niche, num_ideas)

            # –®–∞–≥ 3: –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ –≤–∏—Ä—É—Å–Ω–æ–º—É –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—É
            print("   üìà –†–∞–Ω–∂–∏—Ä—É—é –∏–¥–µ–∏ –ø–æ –≤–∏—Ä—É—Å–Ω–æ–º—É –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—É...")
            ranked_ideas = self._rank_by_viral_potential(ideas)

            print(f"   ‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(ranked_ideas)} –∏–¥–µ–π\n")

            return ranked_ideas

        except Exception as e:
            raise ContentAnalyzerError(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∏–¥–µ–π: {str(e)}")

    def _calculate_performance(self, video: Dict) -> float:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç performance score –≤–∏–¥–µ–æ

        –£—á–∏—Ç—ã–≤–∞–µ—Ç:
        - –ü—Ä–æ—Å–º–æ—Ç—Ä—ã
        - Engagement rate
        - –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –ª–∞–π–∫–æ–≤ –∫ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞–º

        Args:
            video: –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –≤–∏–¥–µ–æ

        Returns:
            float: Performance score (0-100)
        """
        try:
            views = video.get('views', 0)
            likes = video.get('likes', 0)
            comments = video.get('comments', 0)
            engagement_rate = video.get('engagement_rate', 0)

            # –ë–∞–∑–æ–≤—ã–π score –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ (–ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∞—è —à–∫–∞–ª–∞)
            import math
            views_score = min(100, math.log10(views + 1) * 20) if views > 0 else 0

            # Engagement score
            engagement_score = min(100, engagement_rate * 20)

            # Like rate score
            like_rate = (likes / views * 100) if views > 0 else 0
            like_score = min(100, like_rate * 20)

            # –ò—Ç–æ–≥–æ–≤—ã–π score (–≤–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞)
            total_score = (
                views_score * 0.4 +      # 40% –≤–µ—Å –Ω–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä—ã
                engagement_score * 0.4 + # 40% –≤–µ—Å –Ω–∞ engagement
                like_score * 0.2         # 20% –≤–µ—Å –Ω–∞ –ª–∞–π–∫–∏
            )

            return round(total_score, 2)

        except Exception as e:
            return 0.0

    def _extract_patterns(self, topics: List[Dict]) -> Dict:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ —É—Å–ø–µ—à–Ω—ã—Ö —Ç–µ–º

        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç:
        - –ß–∞—Å—Ç—ã–µ —Å–ª–æ–≤–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö
        - –î–ª–∏–Ω—É –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–æ–≤
        - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —á–∏—Å–µ–ª
        - –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã

        Args:
            topics: –°–ø–∏—Å–æ–∫ —Ç–µ–º —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏

        Returns:
            Dict: –ü–∞—Ç—Ç–µ—Ä–Ω—ã —É—Å–ø–µ—à–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        """
        try:
            if not topics:
                return {}

            titles = [t['title'] for t in topics]

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ª–æ–≤–∞
            all_words = []
            for title in titles:
                words = re.findall(r'\b[A-Za-z–ê-–Ø–∞-—è]{3,}\b', title.lower())
                all_words.extend(words)

            # –°—Ç–æ–ø-—Å–ª–æ–≤–∞
            stop_words = {
                'the', 'and', 'for', 'are', 'but', 'not', 'you', 'all', 'this', 'that',
                '—ç—Ç–æ', '–∫–∞–∫', '–¥–ª—è', '—á—Ç–æ', '–∏–ª–∏', '–≤—Å–µ', '–±—ã–ª', '–±—ã—Ç—å', '—Ç–∞–∫'
            }

            filtered_words = [w for w in all_words if w not in stop_words]
            word_counter = Counter(filtered_words)

            # –¢–æ–ø —Å–ª–æ–≤–∞
            top_words = [word for word, count in word_counter.most_common(10)]

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            has_questions = sum(1 for t in titles if '?' in t)
            has_numbers = sum(1 for t in titles if re.search(r'\d+', t))
            avg_length = sum(len(t) for t in titles) / len(titles) if titles else 0

            # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã
            emotion_triggers = {
                'shocking': sum(1 for t in titles if any(word in t.lower() for word in ['shocking', '—à–æ–∫–∏—Ä—É—é—â', '–Ω–µ–≤–µ—Ä–æ—è—Ç–Ω'])),
                'secret': sum(1 for t in titles if any(word in t.lower() for word in ['secret', '—Å–µ–∫—Ä–µ—Ç', '—Å–∫—Ä—ã—Ç'])),
                'ultimate': sum(1 for t in titles if any(word in t.lower() for word in ['ultimate', 'best', 'top', '–ª—É—á—à', '—Ç–æ–ø'])),
                'how_to': sum(1 for t in titles if any(word in t.lower() for word in ['how to', '–∫–∞–∫']))
            }

            return {
                'top_keywords': top_words,
                'avg_title_length': int(avg_length),
                'question_percentage': round(has_questions / len(titles) * 100, 1),
                'number_percentage': round(has_numbers / len(titles) * 100, 1),
                'emotion_triggers': emotion_triggers,
                'sample_titles': titles[:5]  # –ü—Ä–∏–º–µ—Ä—ã —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            }

        except Exception as e:
            print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {e}")
            return {}

    async def _generate_ideas_from_patterns(
        self,
        patterns: Dict,
        niche: str,
        num_ideas: int
    ) -> List[Dict]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–¥–µ–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å –ø–æ–º–æ—â—å—é Google Gemini

        Args:
            patterns: –ü–∞—Ç—Ç–µ—Ä–Ω—ã —É—Å–ø–µ—à–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            niche: –ù–∏—à–∞
            num_ideas: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–¥–µ–π

        Returns:
            List[Dict]: –°–ø–∏—Å–æ–∫ –∏–¥–µ–π

        Raises:
            ContentAnalyzerError: –ü—Ä–∏ –æ—à–∏–±–∫–∞—Ö –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        """
        try:
            # –°—Ç—Ä–æ–∏–º –ø—Ä–æ–º–ø—Ç –¥–ª—è Gemini
            patterns_desc = ""
            if patterns:
                patterns_desc = f"""
–ü–ê–¢–¢–ï–†–ù–´ –£–°–ü–ï–®–ù–û–ì–û –ö–û–ù–¢–ï–ù–¢–ê –í –ù–ò–®–ï:
- –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(patterns.get('top_keywords', [])[:5])}
- –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞: {patterns.get('avg_title_length', 50)} —Å–∏–º–≤–æ–ª–æ–≤
- –í–æ–ø—Ä–æ—Å—ã –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö: {patterns.get('question_percentage', 0)}%
- –ß–∏—Å–ª–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö: {patterns.get('number_percentage', 0)}%

–ü–†–ò–ú–ï–†–´ –£–°–ü–ï–®–ù–´–• –ó–ê–ì–û–õ–û–í–ö–û–í:
{chr(10).join('- ' + t for t in patterns.get('sample_titles', [])[:3])}
"""

            prompt = f"""
–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ YouTube –∏ –≤–∏—Ä—É—Å–Ω–æ–º—É –∫–æ–Ω—Ç–µ–Ω—Ç—É. –ì–µ–Ω–µ—Ä–∏—Ä—É–π {num_ideas} –£–ù–ò–ö–ê–õ–¨–ù–´–• –∏–¥–µ–π –¥–ª—è –≤–∏–¥–µ–æ –≤ –Ω–∏—à–µ "{niche}".

{patterns_desc}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –ò–î–ï–Ø–ú:
1. –ö–∞–∂–¥–∞—è –∏–¥–µ—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –£–ù–ò–ö–ê–õ–¨–ù–û–ô –∏ –ö–õ–ò–ö–ê–ë–ï–õ–¨–ù–û–ô
2. –ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–ª–∂–µ–Ω –≤—ã–∑—ã–≤–∞—Ç—å –ª—é–±–æ–ø—ã—Ç—Å—Ç–≤–æ –∏–ª–∏ –æ–±–µ—â–∞—Ç—å –ø–æ–ª—å–∑—É
3. –£—á–∏—Ç—ã–≤–∞–π –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —É—Å–ø–µ—à–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
4. –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã (—É–¥–∏–≤–ª–µ–Ω–∏–µ, –ª—é–±–æ–ø—ã—Ç—Å—Ç–≤–æ, –ø–æ–ª—å–∑–∞)
5. –ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ –∏–∑–±–µ–≥–∞–π –æ–±—â–∏—Ö —Ñ—Ä–∞–∑

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (—Å—Ç—Ä–æ–≥–æ —Å–ª–µ–¥—É–π —ç—Ç–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –¥–ª—è –ö–ê–ñ–î–û–ô –∏–¥–µ–∏):

[IDEA 1]
Title: <–ö–ª–∏–∫–∞–±–µ–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤–∏–¥–µ–æ>
Description: <–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤ 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö>
Target Audience: <–¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è>
Hook: <–ó–∞—Ö–≤–∞—Ç—ã–≤–∞—é—â–∏–π —Ö—É–∫ –¥–ª—è –ø–µ—Ä–≤—ã—Ö 10 —Å–µ–∫—É–Ω–¥>
Difficulty: <easy/medium/hard>

[IDEA 2]
Title: <–ö–ª–∏–∫–∞–±–µ–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤–∏–¥–µ–æ>
Description: <–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤ 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö>
Target Audience: <–¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è>
Hook: <–ó–∞—Ö–≤–∞—Ç—ã–≤–∞—é—â–∏–π —Ö—É–∫ –¥–ª—è –ø–µ—Ä–≤—ã—Ö 10 —Å–µ–∫—É–Ω–¥>
Difficulty: <easy/medium/hard>

... –∏ —Ç–∞–∫ –¥–∞–ª–µ–µ –¥–ª—è –≤—Å–µ—Ö {num_ideas} –∏–¥–µ–π.

–í–ê–ñ–ù–û: –ì–µ–Ω–µ—Ä–∏—Ä—É–π –≤—Å–µ {num_ideas} –∏–¥–µ–π! –ù–µ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–π—Å—è —Ä–∞–Ω—å—à–µ.

–ù–∞—á–∏–Ω–∞–π –≥–µ–Ω–µ—Ä–∞—Ü–∏—é!
"""

            # –í—ã–∑—ã–≤–∞–µ–º Gemini API
            response = self.gemini_model.generate_content(prompt)
            response_text = response.text

            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
            ideas = self._parse_ideas_response(response_text)

            if len(ideas) < num_ideas:
                print(f"   ‚ö†Ô∏è  –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —Ç–æ–ª—å–∫–æ {len(ideas)} –∏–∑ {num_ideas} –∏–¥–µ–π")

            return ideas

        except Exception as e:
            raise ContentAnalyzerError(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–¥–µ–π: {str(e)}")

    def _parse_ideas_response(self, response_text: str) -> List[Dict]:
        """
        –ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç Gemini –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∏–¥–µ–∏

        Args:
            response_text: –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç Gemini

        Returns:
            List[Dict]: –°–ø–∏—Å–æ–∫ –∏–¥–µ–π
        """
        ideas = []

        try:
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∏–¥–µ–∏
            idea_blocks = re.split(r'\[IDEA \d+\]', response_text)

            for block in idea_blocks:
                if not block.strip():
                    continue

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ–ª—è
                title_match = re.search(r'Title:\s*(.+)', block)
                desc_match = re.search(r'Description:\s*(.+?)(?=Target Audience:|Hook:|Difficulty:|$)', block, re.DOTALL)
                audience_match = re.search(r'Target Audience:\s*(.+)', block)
                hook_match = re.search(r'Hook:\s*(.+?)(?=Difficulty:|$)', block, re.DOTALL)
                difficulty_match = re.search(r'Difficulty:\s*(\w+)', block)

                if title_match:
                    idea = {
                        'title': title_match.group(1).strip(),
                        'description': desc_match.group(1).strip() if desc_match else "",
                        'target_audience': audience_match.group(1).strip() if audience_match else "–®–∏—Ä–æ–∫–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è",
                        'hook': hook_match.group(1).strip() if hook_match else "",
                        'difficulty': difficulty_match.group(1).strip().lower() if difficulty_match else "medium",
                        'viral_score': 0,  # –ë—É–¥–µ—Ç –≤—ã—á–∏—Å–ª–µ–Ω –ø–æ–∑–∂–µ
                        'estimated_views': 0  # –ë—É–¥–µ—Ç –≤—ã—á–∏—Å–ª–µ–Ω –ø–æ–∑–∂–µ
                    }
                    ideas.append(idea)

            return ideas

        except Exception as e:
            print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏–¥–µ–π: {e}")
            return []

    def _rank_by_viral_potential(self, ideas: List[Dict]) -> List[Dict]:
        """
        –†–∞–Ω–∂–∏—Ä—É–µ—Ç –∏–¥–µ–∏ –ø–æ –≤–∏—Ä—É—Å–Ω–æ–º—É –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—É

        –§–∞–∫—Ç–æ—Ä—ã –≤–∏—Ä—É—Å–Ω–æ—Å—Ç–∏:
        - –ù–∞–ª–∏—á–∏–µ —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ
        - –î–ª–∏–Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ (–æ–ø—Ç–∏–º—É–º 40-70 —Å–∏–º–≤–æ–ª–æ–≤)
        - –ù–∞–ª–∏—á–∏–µ —á–∏—Å–µ–ª
        - –ù–∞–ª–∏—á–∏–µ –≤–æ–ø—Ä–æ—Å–æ–≤
        - –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –æ–∫—Ä–∞—Å–∫–∞
        - –ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ—Å—Ç—å vs –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω–æ—Å—Ç—å

        Args:
            ideas: –°–ø–∏—Å–æ–∫ –∏–¥–µ–π

        Returns:
            List[Dict]: –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∏–¥–µ–π —Å viral_score
        """
        try:
            for idea in ideas:
                score = 50  # –ë–∞–∑–æ–≤—ã–π score
                title = idea['title']

                # 1. –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ (+20 –±–∞–ª–ª–æ–≤)
                title_length = len(title)
                if 40 <= title_length <= 70:
                    score += 20
                elif 30 <= title_length <= 80:
                    score += 10

                # 2. –ù–∞–ª–∏—á–∏–µ —á–∏—Å–µ–ª (+15 –±–∞–ª–ª–æ–≤)
                if re.search(r'\d+', title):
                    score += 15

                # 3. –í–æ–ø—Ä–æ—Å –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ (+15 –±–∞–ª–ª–æ–≤)
                if '?' in title:
                    score += 15

                # 4. –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã (+10 –±–∞–ª–ª–æ–≤ –∫–∞–∂–¥—ã–π, –º–∞–∫—Å 30)
                triggers = {
                    '—à–æ–∫–∏—Ä—É—é—â': ['—à–æ–∫', '–Ω–µ–≤–µ—Ä–æ—è—Ç–Ω', '—É–¥–∏–≤–∏—Ç–µ–ª—å–Ω', 'shocking', 'unbelievable'],
                    '—Å–µ–∫—Ä–µ—Ç': ['—Å–µ–∫—Ä–µ—Ç', '—Å–∫—Ä—ã—Ç', 'secret', 'hidden'],
                    '—Ç–æ–ø': ['–ª—É—á—à', '—Ç–æ–ø', 'best', 'top', 'ultimate'],
                    '–∫–∞–∫': ['–∫–∞–∫', 'how to', 'guide'],
                    '–ø–æ—á–µ–º—É': ['–ø–æ—á–µ–º—É', 'why', 'reason']
                }

                trigger_count = 0
                for trigger_type, keywords in triggers.items():
                    if any(keyword in title.lower() for keyword in keywords):
                        score += 10
                        trigger_count += 1
                        if trigger_count >= 3:
                            break

                # 5. –ù–∞–ª–∏—á–∏–µ Hook (+10 –±–∞–ª–ª–æ–≤)
                if idea.get('hook'):
                    score += 10

                # 6. –ü—Ä–æ—Å—Ç–æ—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è (easy +5, medium 0, hard -5)
                difficulty = idea.get('difficulty', 'medium')
                if difficulty == 'easy':
                    score += 5
                elif difficulty == 'hard':
                    score -= 5

                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º score –¥–æ 100
                score = min(100, score)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º score
                idea['viral_score'] = score

                # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ score
                import random
                base_views = 1000 if difficulty == 'easy' else 500 if difficulty == 'medium' else 300
                idea['estimated_views'] = int(base_views * (score / 50) * random.uniform(0.8, 1.5))

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ viral_score
            ideas.sort(key=lambda x: x['viral_score'], reverse=True)

            return ideas

        except Exception as e:
            print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            return ideas

    async def analyze_seasonal_trends(self, niche: str) -> Dict:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–µ–∑–æ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã –≤ –Ω–∏—à–µ

        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç:
        - –¢–µ–∫—É—â–∏–µ —Ç—Ä–µ–Ω–¥—ã (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π)
        - –†–∞—Å—Ç—É—â–∏–µ —Ç–µ–º—ã
        - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏

        Args:
            niche: –ù–∏—à–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            Dict: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç—Ä–µ–Ω–¥–∞—Ö
                - current_trends: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—É—â–∏—Ö —Ç—Ä–µ–Ω–¥–æ–≤
                - rising_topics: –†–∞—Å—Ç—É—â–∏–µ —Ç–µ–º—ã
                - best_time_to_publish: –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è
                - seasonal_insights: –°–µ–∑–æ–Ω–Ω—ã–µ –∏–Ω—Å–∞–π—Ç—ã

        Raises:
            ContentAnalyzerError: –ü—Ä–∏ –æ—à–∏–±–∫–∞—Ö –∞–Ω–∞–ª–∏–∑–∞
        """
        try:
            print(f"\nüîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–µ–∑–æ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã –≤ –Ω–∏—à–µ: {niche}")

            # –ü–æ–ª—É—á–∞–µ–º –Ω–µ–¥–∞–≤–Ω–∏–µ –≤–∏–¥–µ–æ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π)
            request = self.youtube_analyzer.youtube.search().list(
                part='snippet',
                q=niche,
                type='video',
                maxResults=30,
                order='date',
                publishedAfter=(datetime.now() - timedelta(days=7)).isoformat() + 'Z'
            )
            response = request.execute()

            # –°–æ–±–∏—Ä–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
            recent_titles = [item['snippet']['title'] for item in response['items']]

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            all_words = []
            for title in recent_titles:
                words = re.findall(r'\b[A-Za-z–ê-–Ø–∞-—è]{4,}\b', title.lower())
                all_words.extend(words)

            # –°—Ç–æ–ø-—Å–ª–æ–≤–∞
            stop_words = {
                'the', 'and', 'for', 'are', 'but', 'not', 'you', 'all', 'this', 'that',
                '—ç—Ç–æ', '–∫–∞–∫', '–¥–ª—è', '—á—Ç–æ', '–∏–ª–∏', '–≤—Å–µ', '–±—ã–ª', '–±—ã—Ç—å'
            }

            filtered_words = [w for w in all_words if w not in stop_words]
            word_counter = Counter(filtered_words)

            current_trends = [word for word, count in word_counter.most_common(10)]

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–µ–∑–æ–Ω–Ω—ã–µ –∏–Ω—Å–∞–π—Ç—ã —Å –ø–æ–º–æ—â—å—é AI
            month = datetime.now().strftime('%B')

            prompt = f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–µ–∑–æ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã –¥–ª—è –Ω–∏—à–∏ "{niche}" –≤ –º–µ—Å—è—Ü–µ {month}.

–¢–ï–ö–£–©–ò–ï –ü–û–ü–£–õ–Ø–†–ù–´–ï –¢–ï–ú–´: {', '.join(current_trends[:5])}

–î–∞–π –∫—Ä–∞—Ç–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
1. –ö–∞–∫–∏–µ —Ç–µ–º—ã —Å–µ–π—á–∞—Å –∞–∫—Ç—É–∞–ª—å–Ω—ã?
2. –ö–∞–∫–∏–µ —Ç–µ–º—ã –±—É–¥—É—Ç —Ä–∞—Å—Ç–∏ –≤ –±–ª–∏–∂–∞–π—à–∏–µ 2-4 –Ω–µ–¥–µ–ª–∏?
3. –õ—É—á—à–µ–µ –≤—Ä–µ–º—è –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –≤ —ç—Ç–æ–π –Ω–∏—à–µ (–¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏ –∏ –≤—Ä–µ–º—è)?

–û—Ç–≤–µ—Ç –¥–∞–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ:

[CURRENT]
<–°–ø–∏—Å–æ–∫ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö —Ç–µ–º —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é>

[RISING]
<–°–ø–∏—Å–æ–∫ —Ä–∞—Å—Ç—É—â–∏—Ö —Ç–µ–º —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é>

[TIMING]
<–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏>

[INSIGHTS]
<–ö—Ä–∞—Ç–∫–∏–µ —Å–µ–∑–æ–Ω–Ω—ã–µ –∏–Ω—Å–∞–π—Ç—ã 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è>
"""

            response = self.gemini_model.generate_content(prompt)
            result_text = response.text

            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            current_match = re.search(r'\[CURRENT\](.*?)(?=\[|$)', result_text, re.DOTALL)
            rising_match = re.search(r'\[RISING\](.*?)(?=\[|$)', result_text, re.DOTALL)
            timing_match = re.search(r'\[TIMING\](.*?)(?=\[|$)', result_text, re.DOTALL)
            insights_match = re.search(r'\[INSIGHTS\](.*?)(?=\[|$)', result_text, re.DOTALL)

            return {
                'current_trends': [t.strip() for t in current_match.group(1).split(',') if t.strip()] if current_match else current_trends,
                'rising_topics': [t.strip() for t in rising_match.group(1).split(',') if t.strip()] if rising_match else [],
                'best_time_to_publish': timing_match.group(1).strip() if timing_match else "–°–µ—Ä–µ–¥–∏–Ω–∞ –Ω–µ–¥–µ–ª–∏, 14:00-18:00",
                'seasonal_insights': insights_match.group(1).strip() if insights_match else "",
                'analyzed_at': datetime.now().isoformat()
            }

        except Exception as e:
            raise ContentAnalyzerError(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–µ–∑–æ–Ω–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤: {str(e)}")
