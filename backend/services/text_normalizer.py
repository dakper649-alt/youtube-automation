"""
–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–π –æ–∑–≤—É—á–∫–∏
–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Ü–∏—Ñ—Ä—ã, –¥–∞—Ç—ã, —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è –≤ —á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
"""

import re
from typing import Dict, List


class TextNormalizer:
    """
    –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–µ–∫—Å—Ç–∞ –¥–ª—è TTS

    –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
    - –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ü–∏—Ñ—Ä –≤ —Å–ª–æ–≤–∞
    - –†–∞—Å–∫—Ä—ã—Ç–∏–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π
    - –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏–µ –¥–∞—Ç
    - –£–¥–∞–ª–µ–Ω–∏–µ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤
    - –ü—Ä–æ–≤–µ—Ä–∫–∞ —è–∑—ã–∫–∞
    - –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
    """

    def __init__(self, language: str = 'ru'):
        self.language = language

        # –°–ª–æ–≤–∞—Ä—å —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
        self.ru_abbreviations = {
            # –û–±—â–∏–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è
            '—Ç.–¥.': '—Ç–∞–∫ –¥–∞–ª–µ–µ',
            '—Ç. –¥.': '—Ç–∞–∫ –¥–∞–ª–µ–µ',
            '–∏ —Ç.–¥.': '–∏ —Ç–∞–∫ –¥–∞–ª–µ–µ',
            '–∏ —Ç. –¥.': '–∏ —Ç–∞–∫ –¥–∞–ª–µ–µ',
            '—Ç.–ø.': '—Ç–æ–º—É –ø–æ–¥–æ–±–Ω–æ–µ',
            '—Ç. –ø.': '—Ç–æ–º—É –ø–æ–¥–æ–±–Ω–æ–µ',
            '–∏ —Ç.–ø.': '–∏ —Ç–æ–º—É –ø–æ–¥–æ–±–Ω–æ–µ',
            '–∏ —Ç. –ø.': '–∏ —Ç–æ–º—É –ø–æ–¥–æ–±–Ω–æ–µ',
            '—Ç.–µ.': '—Ç–æ –µ—Å—Ç—å',
            '—Ç. –µ.': '—Ç–æ –µ—Å—Ç—å',
            '–∏ —Ç.–µ.': '–∏ —Ç–æ –µ—Å—Ç—å',

            # –ï–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
            '–∫–º': '–∫–∏–ª–æ–º–µ—Ç—Ä–æ–≤',
            '–º': '–º–µ—Ç—Ä–æ–≤',
            '—Å–º': '—Å–∞–Ω—Ç–∏–º–µ—Ç—Ä–æ–≤',
            '–∫–≥': '–∫–∏–ª–æ–≥—Ä–∞–º–º–æ–≤',
            '–≥': '–≥—Ä–∞–º–º–æ–≤',
            '–ª': '–ª–∏—Ç—Ä–æ–≤',
            '–º–ª': '–º–∏–ª–ª–∏–ª–∏—Ç—Ä–æ–≤',

            # –í–∞–ª—é—Ç—ã (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å—Ç–æ—è—Ç –ü–û–°–õ–ï —á–∏—Å–ª–∞)
            '—Ä—É–±.': '—Ä—É–±–ª–µ–π',
            '—Ä—É–±': '—Ä—É–±–ª–µ–π',
            '—Ä.': '—Ä—É–±–ª–µ–π',
            '–∫–æ–ø.': '–∫–æ–ø–µ–µ–∫',

            # –í—Ä–µ–º–µ–Ω–Ω—ã–µ
            '–≥.': '–≥–æ–¥–∞',
            '–º–∏–Ω.': '–º–∏–Ω—É—Ç',
            '—Å–µ–∫.': '—Å–µ–∫—É–Ω–¥',
            '—á.': '—á–∞—Å–æ–≤',

            # –¢–∏—Ç—É–ª—ã –∏ –æ–±—Ä–∞—â–µ–Ω–∏—è
            '–≥-–Ω': '–≥–æ—Å–ø–æ–¥–∏–Ω',
            '–≥-–∂–∞': '–≥–æ—Å–ø–æ–∂–∞',
            '–¥-—Ä': '–¥–æ–∫—Ç–æ—Ä',
            '–ø—Ä–æ—Ñ.': '–ø—Ä–æ—Ñ–µ—Å—Å–æ—Ä',

            # –ü—Ä–æ—á–µ–µ
            '–∏ –¥—Ä.': '–∏ –¥—Ä—É–≥–∏–µ',
            '–Ω–∞–ø—Ä.': '–Ω–∞–ø—Ä–∏–º–µ—Ä',
            '—Å–º.': '—Å–º–æ—Ç—Ä–∏—Ç–µ',
            '—Å—Ä.': '—Å—Ä–∞–≤–Ω–∏—Ç–µ',
            'vs': '–ø—Ä–æ—Ç–∏–≤',
            'vs.': '–ø—Ä–æ—Ç–∏–≤'
        }

        # –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è
        self.en_abbreviations = {
            'etc.': 'etcetera',
            'e.g.': 'for example',
            'i.e.': 'that is',
            'vs': 'versus',
            'vs.': 'versus',
            'Mr.': 'Mister',
            'Mrs.': 'Missis',
            'Dr.': 'Doctor',
            'Prof.': 'Professor',
            'km': 'kilometers',
            'm': 'meters',
            'cm': 'centimeters',
            'kg': 'kilograms'
        }

    def normalize_for_tts(self, text: str) -> str:
        """
        –ü–æ–ª–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è TTS

        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç

        Returns:
            –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –≥–æ—Ç–æ–≤—ã–π –¥–ª—è –æ–∑–≤—É—á–∫–∏
        """

        print(f"üîß –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ–∑–≤—É—á–∫–∏...")

        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —è–∑—ã–∫–∞
        detected_lang = self._detect_language(text)
        if detected_lang != self.language:
            print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –û–±–Ω–∞—Ä—É–∂–µ–Ω —è–∑—ã–∫ {detected_lang}, –æ–∂–∏–¥–∞–ª—Å—è {self.language}")

        # 2. –£–¥–∞–ª–µ–Ω–∏–µ markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        text = self._remove_markdown(text)

        # 3. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è URL –≤ —á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
        text = self._normalize_urls(text)

        # 4. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è email –≤ —á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
        text = self._normalize_emails(text)

        # 5. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞—Ç (–ö–†–ò–¢–ò–ß–ù–û!)
        text = self._normalize_dates(text)

        # 6. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ü–∏—Ñ—Ä –≤ —Å–ª–æ–≤–∞ (–ö–†–ò–¢–ò–ß–ù–û!)
        text = self._numbers_to_words(text)

        # 7. –†–∞—Å–∫—Ä—ã—Ç–∏–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π (–ö–†–ò–¢–ò–ß–ù–û!)
        text = self._expand_abbreviations(text)

        # 8. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        text = self._normalize_math_symbols(text)

        # 9. –£–¥–∞–ª–µ–Ω–∏–µ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤ –∫–æ—Ç–æ—Ä—ã–µ AI –ø–ª–æ—Ö–æ —á–∏—Ç–∞–µ—Ç
        text = self._remove_problematic_chars(text)

        # 10. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ –¥–ª—è –ø–∞—É–∑
        text = self._normalize_punctuation(text)

        # 11. –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
        text = self._final_cleanup(text)

        print(f"‚úÖ –¢–µ–∫—Å—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω!")

        return text

    def _detect_language(self, text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —è–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞"""
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞
        russian_chars = len(re.findall(r'[–∞-—è–ê-–Ø—ë–Å]', text))
        english_chars = len(re.findall(r'[a-zA-Z]', text))

        if russian_chars > english_chars:
            return 'ru'
        elif english_chars > russian_chars:
            return 'en'
        return self.language

    def _remove_markdown(self, text: str) -> str:
        """–£–¥–∞–ª—è–µ—Ç markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        # –£–¥–∞–ª—è–µ–º ** (bold)
        text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)
        # –£–¥–∞–ª—è–µ–º * (italic)
        text = re.sub(r'\*(.*?)\*', r'\1', text)
        # –£–¥–∞–ª—è–µ–º _ (italic)
        text = re.sub(r'_(.*?)_', r'\1', text)
        # –£–¥–∞–ª—è–µ–º # (headers)
        text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)
        # –£–¥–∞–ª—è–µ–º [text](url)
        text = re.sub(r'\[(.*?)\]\(.*?\)', r'\1', text)

        return text

    def _normalize_urls(self, text: str) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç URL –≤ —á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç"""
        # –ó–∞–º–µ–Ω—è–µ–º –ø–æ–ª–Ω—ã–µ URL
        text = re.sub(
            r'https?://(?:www\.)?([a-zA-Z0-9-]+\.[a-zA-Z]{2,})',
            r'—Å–∞–π—Ç \1',
            text
        )
        return text

    def _normalize_emails(self, text: str) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç email –≤ —á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç"""
        def email_to_speech(match):
            email = match.group(0)
            local, domain = email.split('@')
            return f"{local} —Å–æ–±–∞–∫–∞ {domain.replace('.', ' —Ç–æ—á–∫–∞ ')}"

        text = re.sub(
            r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
            email_to_speech,
            text
        )
        return text

    def _normalize_dates(self, text: str) -> str:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –¥–∞—Ç—ã –≤ —á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
        –ö–†–ò–¢–ò–ß–ù–û –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏—è!

        –ü—Ä–∏–º–µ—Ä—ã:
        - "01.01.2024" ‚Üí "–ø–µ—Ä–≤–æ–µ —è–Ω–≤–∞—Ä—è –¥–≤–µ —Ç—ã—Å—è—á–∏ –¥–≤–∞–¥—Ü–∞—Ç—å —á–µ—Ç–≤—ë—Ä—Ç–æ–≥–æ –≥–æ–¥–∞"
        - "2024 –≥–æ–¥" ‚Üí "–¥–≤–µ —Ç—ã—Å—è—á–∏ –¥–≤–∞–¥—Ü–∞—Ç—å —á–µ—Ç–≤—ë—Ä—Ç—ã–π –≥–æ–¥"
        - "–≤ 2020-2023 –≥–æ–¥–∞—Ö" ‚Üí "–≤ –¥–≤–µ —Ç—ã—Å—è—á–∏ –¥–≤–∞–¥—Ü–∞—Ç–æ–º - –¥–≤–µ —Ç—ã—Å—è—á–∏ –¥–≤–∞–¥—Ü–∞—Ç—å —Ç—Ä–µ—Ç—å–µ–º –≥–æ–¥–∞—Ö"
        """

        if self.language == 'ru':
            # –ú–µ—Å—è—Ü—ã –≤ —Ä–æ–¥–∏—Ç–µ–ª—å–Ω–æ–º –ø–∞–¥–µ–∂–µ (–¥–ª—è "15 —è–Ω–≤–∞—Ä—è")
            months_genitive = {
                '01': '—è–Ω–≤–∞—Ä—è', '02': '—Ñ–µ–≤—Ä–∞–ª—è', '03': '–º–∞—Ä—Ç–∞',
                '04': '–∞–ø—Ä–µ–ª—è', '05': '–º–∞—è', '06': '–∏—é–Ω—è',
                '07': '–∏—é–ª—è', '08': '–∞–≤–≥—É—Å—Ç–∞', '09': '—Å–µ–Ω—Ç—è–±—Ä—è',
                '10': '–æ–∫—Ç—è–±—Ä—è', '11': '–Ω–æ—è–±—Ä—è', '12': '–¥–µ–∫–∞–±—Ä—è',
                '1': '—è–Ω–≤–∞—Ä—è', '2': '—Ñ–µ–≤—Ä–∞–ª—è', '3': '–º–∞—Ä—Ç–∞',
                '4': '–∞–ø—Ä–µ–ª—è', '5': '–º–∞—è', '6': '–∏—é–Ω—è',
                '7': '–∏—é–ª—è', '8': '–∞–≤–≥—É—Å—Ç–∞', '9': '—Å–µ–Ω—Ç—è–±—Ä—è'
            }

            # –î–∞—Ç—ã —Ñ–æ—Ä–º–∞—Ç–∞ DD.MM.YYYY –∏–ª–∏ DD/MM/YYYY
            def date_to_words(match):
                day, month, year = match.groups()
                day_word = self._number_to_ordinal(int(day))
                month_word = months_genitive.get(month, month)
                year_word = self._year_to_words(int(year))
                return f"{day_word} {month_word} {year_word} –≥–æ–¥–∞"

            text = re.sub(
                r'(\d{1,2})[./](\d{1,2})[./](\d{4})',
                date_to_words,
                text
            )

            # –ì–æ–¥—ã "2024 –≥." –∏–ª–∏ "2024 –≥–æ–¥"
            def year_to_words(match):
                year = int(match.group(1))
                return self._year_to_words(year) + ' –≥–æ–¥'

            text = re.sub(r'(\d{4})\s*(?:–≥\.|–≥–æ–¥)', year_to_words, text)

            # –î–∏–∞–ø–∞–∑–æ–Ω—ã –ª–µ—Ç "2020-2024"
            def year_range_to_words(match):
                year1 = int(match.group(1))
                year2 = int(match.group(2))
                return f"{self._year_to_words(year1)} - {self._year_to_words(year2)}"

            text = re.sub(r'(\d{4})-(\d{4})', year_range_to_words, text)

        return text

    def _year_to_words(self, year: int) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≥–æ–¥ –≤ —Å–ª–æ–≤–∞ (—Ä—É—Å—Å–∫–∏–π)"""
        if year >= 2000:
            thousands = year // 1000
            remainder = year % 1000

            if remainder == 0:
                return "–¥–≤–µ —Ç—ã—Å—è—á–∏"

            result = "–¥–≤–µ —Ç—ã—Å—è—á–∏"

            if remainder >= 100:
                hundreds = remainder // 100
                remainder = remainder % 100
                hundreds_words = {
                    1: '—Å—Ç–æ', 2: '–¥–≤–µ—Å—Ç–∏', 3: '—Ç—Ä–∏—Å—Ç–∞', 4: '—á–µ—Ç—ã—Ä–µ—Å—Ç–∞',
                    5: '–ø—è—Ç—å—Å–æ—Ç', 6: '—à–µ—Å—Ç—å—Å–æ—Ç', 7: '—Å–µ–º—å—Å–æ—Ç',
                    8: '–≤–æ—Å–µ–º—å—Å–æ—Ç', 9: '–¥–µ–≤—è—Ç—å—Å–æ—Ç'
                }
                result += f" {hundreds_words.get(hundreds, '')}"

            if remainder > 0:
                result += f" {self._simple_num_to_words(remainder)}"

            return result.strip()
        else:
            return self._simple_num_to_words(year)

    def _simple_num_to_words(self, num: int) -> str:
        """–ü—Ä–æ—Å—Ç–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —á–∏—Å–ª–∞ –≤ —Å–ª–æ–≤–∞ (–±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫)"""
        ones = ['', '–æ–¥–∏–Ω', '–¥–≤–∞', '—Ç—Ä–∏', '—á–µ—Ç—ã—Ä–µ', '–ø—è—Ç—å', '—à–µ—Å—Ç—å', '—Å–µ–º—å', '–≤–æ—Å–µ–º—å', '–¥–µ–≤—è—Ç—å']
        tens = ['', '', '–¥–≤–∞–¥—Ü–∞—Ç—å', '—Ç—Ä–∏–¥—Ü–∞—Ç—å', '—Å–æ—Ä–æ–∫', '–ø—è—Ç—å–¥–µ—Å—è—Ç', '—à–µ—Å—Ç—å–¥–µ—Å—è—Ç', '—Å–µ–º—å–¥–µ—Å—è—Ç', '–≤–æ—Å–µ–º—å–¥–µ—Å—è—Ç', '–¥–µ–≤—è–Ω–æ—Å—Ç–æ']
        teens = ['–¥–µ—Å—è—Ç—å', '–æ–¥–∏–Ω–Ω–∞–¥—Ü–∞—Ç—å', '–¥–≤–µ–Ω–∞–¥—Ü–∞—Ç—å', '—Ç—Ä–∏–Ω–∞–¥—Ü–∞—Ç—å', '—á–µ—Ç—ã—Ä–Ω–∞–¥—Ü–∞—Ç—å', '–ø—è—Ç–Ω–∞–¥—Ü–∞—Ç—å', '—à–µ—Å—Ç–Ω–∞–¥—Ü–∞—Ç—å', '—Å–µ–º–Ω–∞–¥—Ü–∞—Ç—å', '–≤–æ—Å–µ–º–Ω–∞–¥—Ü–∞—Ç—å', '–¥–µ–≤—è—Ç–Ω–∞–¥—Ü–∞—Ç—å']

        if num == 0:
            return '–Ω–æ–ª—å'
        if num < 10:
            return ones[num]
        if num < 20:
            return teens[num - 10]
        if num < 100:
            return (tens[num // 10] + ' ' + ones[num % 10]).strip()
        return str(num)

    def _number_to_ordinal(self, num: int) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —á–∏—Å–ª–æ –≤ –ø–æ—Ä—è–¥–∫–æ–≤–æ–µ —á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–µ"""
        ordinals = {
            1: '–ø–µ—Ä–≤–æ–µ', 2: '–≤—Ç–æ—Ä–æ–µ', 3: '—Ç—Ä–µ—Ç—å–µ', 4: '—á–µ—Ç–≤—ë—Ä—Ç–æ–µ',
            5: '–ø—è—Ç–æ–µ', 6: '—à–µ—Å—Ç–æ–µ', 7: '—Å–µ–¥—å–º–æ–µ', 8: '–≤–æ—Å—å–º–æ–µ',
            9: '–¥–µ–≤—è—Ç–æ–µ', 10: '–¥–µ—Å—è—Ç–æ–µ', 11: '–æ–¥–∏–Ω–Ω–∞–¥—Ü–∞—Ç–æ–µ',
            12: '–¥–≤–µ–Ω–∞–¥—Ü–∞—Ç–æ–µ', 13: '—Ç—Ä–∏–Ω–∞–¥—Ü–∞—Ç–æ–µ', 14: '—á–µ—Ç—ã—Ä–Ω–∞–¥—Ü–∞—Ç–æ–µ',
            15: '–ø—è—Ç–Ω–∞–¥—Ü–∞—Ç–æ–µ', 16: '—à–µ—Å—Ç–Ω–∞–¥—Ü–∞—Ç–æ–µ', 17: '—Å–µ–º–Ω–∞–¥—Ü–∞—Ç–æ–µ',
            18: '–≤–æ—Å–µ–º–Ω–∞–¥—Ü–∞—Ç–æ–µ', 19: '–¥–µ–≤—è—Ç–Ω–∞–¥—Ü–∞—Ç–æ–µ', 20: '–¥–≤–∞–¥—Ü–∞—Ç–æ–µ',
            21: '–¥–≤–∞–¥—Ü–∞—Ç—å –ø–µ—Ä–≤–æ–µ', 22: '–¥–≤–∞–¥—Ü–∞—Ç—å –≤—Ç–æ—Ä–æ–µ', 23: '–¥–≤–∞–¥—Ü–∞—Ç—å —Ç—Ä–µ—Ç—å–µ',
            24: '–¥–≤–∞–¥—Ü–∞—Ç—å —á–µ—Ç–≤—ë—Ä—Ç–æ–µ', 25: '–¥–≤–∞–¥—Ü–∞—Ç—å –ø—è—Ç–æ–µ', 26: '–¥–≤–∞–¥—Ü–∞—Ç—å —à–µ—Å—Ç–æ–µ',
            27: '–¥–≤–∞–¥—Ü–∞—Ç—å —Å–µ–¥—å–º–æ–µ', 28: '–¥–≤–∞–¥—Ü–∞—Ç—å –≤–æ—Å—å–º–æ–µ', 29: '–¥–≤–∞–¥—Ü–∞—Ç—å –¥–µ–≤—è—Ç–æ–µ',
            30: '—Ç—Ä–∏–¥—Ü–∞—Ç–æ–µ', 31: '—Ç—Ä–∏–¥—Ü–∞—Ç—å –ø–µ—Ä–≤–æ–µ'
        }
        return ordinals.get(num, str(num))

    def _numbers_to_words(self, text: str) -> str:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –í–°–ï —Ü–∏—Ñ—Ä—ã –≤ —Å–ª–æ–≤–∞
        –ö–†–ò–¢–ò–ß–ù–û –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏—è!
        """

        def convert_number(match):
            number_str = match.group(0)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –Ω–µ —á–∞—Å—Ç—å –¥–∞—Ç—ã (—É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            start = max(0, match.start() - 10)
            end = min(len(text), match.end() + 10)
            context = text[start:end]

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ —ç—Ç–æ —á–∞—Å—Ç—å URL, email, –∏ —Ç.–¥.
            if any(char in context for char in ['@', 'http', '.com', '.ru']):
                return number_str

            try:
                # –î–µ—Å—è—Ç–∏—á–Ω—ã–µ —á–∏—Å–ª–∞
                if '.' in number_str or ',' in number_str:
                    number_str = number_str.replace(',', '.')
                    num = float(number_str)

                    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Ü–µ–ª—É—é –∏ –¥—Ä–æ–±–Ω—É—é —á–∞—Å—Ç—å
                    integer_part = int(num)
                    decimal_part = str(num).split('.')[1] if '.' in str(num) else ''

                    result = self._simple_num_to_words(integer_part)

                    if decimal_part:
                        result += ' —Ü–µ–ª—ã—Ö '
                        for digit in decimal_part:
                            result += self._simple_num_to_words(int(digit)) + ' '

                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑—Ä—è–¥
                        decimal_places = len(decimal_part)
                        if decimal_places == 1:
                            result += '–¥–µ—Å—è—Ç—ã—Ö'
                        elif decimal_places == 2:
                            result += '—Å–æ—Ç—ã—Ö'
                        elif decimal_places == 3:
                            result += '—Ç—ã—Å—è—á–Ω—ã—Ö'

                    return result

                # –¶–µ–ª—ã–µ —á–∏—Å–ª–∞
                else:
                    num = int(number_str)
                    return self._simple_num_to_words(num)

            except:
                return number_str

        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —á–∏—Å–ª–∞
        text = re.sub(r'\b\d+(?:[.,]\d+)?\b', convert_number, text)

        return text

    def _expand_abbreviations(self, text: str) -> str:
        """–†–∞—Å–∫—Ä—ã–≤–∞–µ—Ç –≤—Å–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è"""

        abbreviations = self.ru_abbreviations if self.language == 'ru' else self.en_abbreviations

        for abbr, full_form in abbreviations.items():
            # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (—Å –≥—Ä–∞–Ω–∏—Ü–∞–º–∏ —Å–ª–æ–≤)
            pattern = r'\b' + re.escape(abbr) + r'\b'
            text = re.sub(pattern, full_form, text, flags=re.IGNORECASE)

        return text

    def _normalize_math_symbols(self, text: str) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã –≤ —Å–ª–æ–≤–∞"""

        symbols = {
            '+': ' –ø–ª—é—Å ',
            '‚àí': ' –º–∏–Ω—É—Å ',
            '-': ' –º–∏–Ω—É—Å ',
            '√ó': ' —É–º–Ω–æ–∂–∏—Ç—å –Ω–∞ ',
            '√∑': ' –¥–µ–ª–∏—Ç—å –Ω–∞ ',
            '=': ' —Ä–∞–≤–Ω–æ ',
            '‚âà': ' –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–≤–Ω–æ ',
            '‚â†': ' –Ω–µ —Ä–∞–≤–Ω–æ ',
            '<': ' –º–µ–Ω—å—à–µ ',
            '>': ' –±–æ–ª—å—à–µ ',
            '‚â§': ' –º–µ–Ω—å—à–µ –∏–ª–∏ —Ä–∞–≤–Ω–æ ',
            '‚â•': ' –±–æ–ª—å—à–µ –∏–ª–∏ —Ä–∞–≤–Ω–æ ',
            '%': ' –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤',
            '‚Ññ': ' –Ω–æ–º–µ—Ä ',
            '¬∞': ' –≥—Ä–∞–¥—É—Å–æ–≤'
        }

        for symbol, word in symbols.items():
            text = text.replace(symbol, word)

        return text

    def _remove_problematic_chars(self, text: str) -> str:
        """–£–¥–∞–ª—è–µ—Ç —Å–∏–º–≤–æ–ª—ã –∫–æ—Ç–æ—Ä—ã–µ AI –ø–ª–æ—Ö–æ —á–∏—Ç–∞–µ—Ç"""

        # –£–¥–∞–ª—è–µ–º emoji
        text = re.sub(r'[^\w\s\.,!?;:\-‚Äî‚Äì()¬´¬ª""\'`]', '', text, flags=re.UNICODE)

        # –ó–∞–º–µ–Ω—è–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∏–¥—ã –∫–∞–≤—ã—á–µ–∫ –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ
        text = text.replace('¬´', '"').replace('¬ª', '"')
        text = text.replace('"', '"').replace('"', '"')
        text = text.replace(''', "'").replace(''', "'")

        # –ó–∞–º–µ–Ω—è–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∏–¥—ã —Ç–∏—Ä–µ –Ω–∞ –¥–µ—Ñ–∏—Å
        text = text.replace('‚Äî', '-').replace('‚Äì', '-')

        return text

    def _normalize_punctuation(self, text: str) -> str:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø–∞—É–∑

        –ü–∞—É–∑–∞ –≤ TTS –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∑–Ω–∞–∫–∞ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è:
        - –¢–æ—á–∫–∞: –¥–ª–∏–Ω–Ω–∞—è –ø–∞—É–∑–∞
        - –ó–∞–ø—è—Ç–∞—è: –∫–æ—Ä–æ—Ç–∫–∞—è –ø–∞—É–∑–∞
        - –ú–Ω–æ–≥–æ—Ç–æ—á–∏–µ: –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω–∞—è –ø–∞—É–∑–∞
        """

        # –ó–∞–º–µ–Ω—è–µ–º –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ –Ω–∞ —Ç–æ—á–∫—É (—á—Ç–æ–±—ã –ø–∞—É–∑—ã –Ω–µ –±—ã–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–º–∏)
        text = text.replace('...', '.')
        text = text.replace('‚Ä¶', '.')

        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –ø–µ—Ä–µ–¥ –∑–Ω–∞–∫–∞–º–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        text = re.sub(r'\s+([.,!?;:])', r'\1', text)

        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–±–µ–ª –ø–æ—Å–ª–µ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
        text = re.sub(r'([.,!?;:])([^\s])', r'\1 \2', text)

        # –£–¥–∞–ª—è–µ–º –¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
        text = re.sub(r'\s{2,}', ' ', text)

        # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫
        text = '\n'.join(line.strip() for line in text.split('\n'))

        return text

    def _final_cleanup(self, text: str) -> str:
        """–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"""

        # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        lines = [line for line in text.split('\n') if line.strip()]
        text = '\n'.join(lines)

        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        text = re.sub(r'\s+', ' ', text)

        # Trim
        text = text.strip()

        return text

    def validate_for_tts(self, text: str) -> Dict:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥ –æ–∑–≤—É—á–∫–æ–π

        Returns:
            dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏
        """

        issues = []
        warnings = []

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 1: –û—Å—Ç–∞–ª–∏—Å—å –ª–∏ —Ü–∏—Ñ—Ä—ã
        if re.search(r'\d', text):
            remaining_numbers = re.findall(r'\d+', text)
            warnings.append(f"–û—Å—Ç–∞–ª–∏—Å—å —Ü–∏—Ñ—Ä—ã: {', '.join(remaining_numbers[:5])}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 2: –û—Å—Ç–∞–ª–∏—Å—å –ª–∏ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è
        common_abbrs = ['—Ç.–¥.', '—Ç.–ø.', '—Ç.–µ.', '–∏ —Ç.–¥.', '–∏ —Ç.–ø.']
        for abbr in common_abbrs:
            if abbr in text:
                issues.append(f"–ù–µ —Ä–∞—Å–∫—Ä—ã—Ç–æ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ: {abbr}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 3: –û—Å—Ç–∞–ª–∏—Å—å –ª–∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
        problematic_chars = ['@', '#', '$', '%', '^', '&', '*']
        found_chars = [char for char in problematic_chars if char in text]
        if found_chars:
            warnings.append(f"–ù–∞–π–¥–µ–Ω—ã —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã: {', '.join(found_chars)}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 4: –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (>200 —Å–∏–º–≤–æ–ª–æ–≤)
        sentences = re.split(r'[.!?]', text)
        long_sentences = [s for s in sentences if len(s) > 200]
        if long_sentences:
            warnings.append(f"–ù–∞–π–¥–µ–Ω–æ {len(long_sentences)} –¥–ª–∏–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (>200 —Å–∏–º–≤–æ–ª–æ–≤)")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 5: –Ø–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–µ
        detected_lang = self._detect_language(text)
        if detected_lang != self.language:
            issues.append(f"–Ø–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞ ({detected_lang}) –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π ({self.language})")

        return {
            'is_valid': len(issues) == 0,
            'issues': issues,
            'warnings': warnings,
            'character_count': len(text),
            'word_count': len(text.split()),
            'detected_language': detected_lang
        }
